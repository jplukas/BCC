# Performance de computadores

Vamos estudar a performance de sistemas de computadores. Para isso, precisamos analisar tanto a performance individual dos componentes de um computador, como as questões sobre como os componentes se comunicam, como os dados trafegam entre os componentes e qual efeito isso tem sobre a performance geral de um computador.

## Fatores que afetam a performance

Um dos principais componentes de um computador é o seu processador. Sobre a performance do processador, podemos analisar os seguintes fatores que a afetam e como poderíamos aumentar o seu desempenho:

1. Velocidade do clock:

   O clock do processador orquestra todas as operações executadas por ele. Portanto, uma frequência maior de clock acarreta em uma quantidade maior de instruções sendo executadas em um intervalo de tempo.  
   Em tese, se pudermos então aumentar a frequência do clock de um processador, podemos também aumentar muito a sua performance. Porém, ao fazermos isso, nos deparamos com alguns obstáculos: Primeiro, há um aumento na potência necessária para se alimentar o processador. Segundo, a quantidade de calor gerado aumenta, o que torna necessária uma melhor dissipação desse calor.

2. Atraso $RC$:

   A velocidade na qual uma instrução pode ser executada é limitada (entre outras coisas) pela velocidade na qual os sinais são transmitidos entre os transistores, o que gera um atraso. Esse atraso é proporcional à distância entre os transistores e ao produto $RC$ entre a resistência e a capacitância do material condutor. Ao diminuir o tamanho do processador, conseguimos diminuir as distâncias entre os transistores, mas a largura do material condutor tende a diminuir, o que gera mais resistência. Além disso, os fios ficam mais próximos, o que por sua vez aumenta a capacitância.

3. Latência e taxa de transferência da memória

   A velocidade na qual o processador processa um conjunto de instruções está intimamente ligada à velocidade na qual ele pode buscar informações, como instruções e os seus respectivos operandos, da memória principal (como estamos falando de computadores que seguem a arquitetura de Von Neumann).

Assim, para atacar esses problemas, foram desenvolvidas várias técnicas para melhorar o desempenho do processador em diferentes frentes. A maioria dessas técnicas envolve algum tipo de paralelismo, ou execução de instruções fora de ordem.  

Como vimos, um computador é composto por várias partes, como processador, memória, dispositivos de entrada/saída e as suas interconexões. A performance do sistema em geral é afetada pela performance de todas as suas componentes, de forma que a velocidade de processamento e execução de instruções do sistema é limitada pela velocidade da sua componente menos performática.  
Um exemplo: na execução de um programa, tipicamente temos várias operações que incluem cálculos aritméticos, desvios de controle e transferências de dados. Geralmente buscar alguma informação na memória principal do computador é algo que demora muito, e se a execução do programa depende daquela informação, então o processador precisa esperar até que a informação esteja disponível para continuar o seu trabalho. À esse tipo de situação damos o nome de *gargalo*. Precisamos então adotar alguma estratégia para evitar esse tipo de situação para poder aproveitar melhor toda a velocidade do processador.

Aqui estão algumas das técnicas utilizadas para aumentar a performance de um computador:

- Pipelining:

  Cada instrução é executada em etapas, que envolvem a busca da instrução na memória, decodificação do código da instrução, busca dos operandos na memória, algum cálculo e etc. Algumas dessas sub-tarefas são independentes (por serem executadas por elementos de hardware diferentes, etc), e podem ser executadas em paralelo, ou ainda, diferentes sub-tarefas de diferentes instruções podem ser executadas ao mesmo tempo. A essa técnica chamamos de *Pipelining*, porque remete às linhas de montagem em indústrias.

- Caching/buffering:

  Para evitar operações custosas de acesso à memória, utilizamos uma espécie de "banco" de memória, ou "memória intermediária", na qual aproveitamos alguma operação de acesso à memória e guardamos informações que o processador provavelmente irá usar, em uma memória intermediária, cujo custo de acesso não é tão grande como o da memória principal.  
  Assim criamos uma espécie de "hierarquia de memória", na qual temos memórias de acesso mais rápido (mas menor capacidade) em diferentes níveis de "proximidade" do processador.

- Execução superescalar:

  É um paralelismo no nível das instruções. Basicamente mais de uma instrução é executada ao mesmo tempo em um mesmo núcleo de processamento. TODO: qual é a diferença entre pipelining e execução superescalar?

- Branch prediction:

  O processador prevê quais instruções têm mais chance de serem executadas (no caso de um desvio, ou *branching*, por exemplo), e as pré-busca na memória, para se manter ocupado.

- Análise de fluxo de dados:

  O processador analisa quais instruções dependem do resultado de outras instruções, ou dados, e gera um itinerário para organizar a execução das instruções, independentemente da ordem original das instruções, de modo a não ficar ocioso.

- Execução especulativa:

  Usando a análise do fluxo de dados e branch prediction, o processador executa instruções que ele prediz que acontecerão, antes que elas aconteçam, e guarda os seus resultados em locais intermediários. Caso uma previsão esteja errada, o processador restaura o seu estado antigo.

## Multicore, MICs e GPGPUs

## Lei de Ahmdal e de Little