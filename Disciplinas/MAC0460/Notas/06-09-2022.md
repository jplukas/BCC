# O Aprendizado é factível?
Podemos aprender uma função *realmente* desconhecida?
 - Impossível, fora do nosso conjunto de dados, a função pode ser literalmente qualquer coisa.
 - O que faremos então?

## Um experimento
Considere uma urna com bolinhas verdes e vermelhas, possivelmente infinitas. A proporção de bolinhas verdes e vermelhas na urna é tal que se escolhermos uma bolinha ao acaso, a probabilidade dessa bolinha ser vermelha é $\mu$ e a probabilidade de ser verde é $1 - \mu$. Assumimos que o valor $\mu$ nos é desconhecido. Tomamos então uma amostra aleatória de $N$ bolinhas independentes desta urna, e observamos então a proporção $\nu$ de bolinhas vermelhas nesta amostra. O que o valor de $\nu$ nos diz sobre o valor de $\mu$?\
Independentemente das cores das $N$ bolinhas que escolhemos, não sabemos nada sobre as cores das bolinhas que não escolhemos, mas podemos esperar que, quanto maior for o tamanho $N$ da nossa amostra, mais perto $\nu$ estará de $\mu$ (provavelmente, pelo menos).\
Para quantificar essa relação entre a proporção $\mu$ e a proporção amostral $\nu$, utilizamos um limite simples, chamado de [*Desigualdade de Hoeffding*](https://en.wikipedia.org/wiki/Hoeffding%27s_inequality). Ela diz que, para qualquer amostra de tamanho $N$, temos:
$$
\mathbb{P}[|\nu - \mu| > \epsilon] \leq 2e ^{-2 \epsilon ^ 2 N} \quad \text{para todo } \epsilon > 0
$${#eq:hoeffding}

Esse resultado nos diz que: para uma certa tolerância $\epsilon > 0$ (desejavelmente pequena), a probabilidade da nossa proporção amostral $\nu$ diferir da proporção da população $\mu$ por um valor maior que $\epsilon$ tem um limite superior, que só depende de $\epsilon$ e do tamanho da nossa amostra - quanto maior o tamanho $N$ da amostra, menor é a probabilidade de obtermos uma estimativa ruim para $\mu$, e quanto menor a nossa tolerância ao erro $\epsilon$, precisamos de uma amostra de tamanho maior para termos certeza que nossa estimativa $\nu$ está perto do valor real (embora desconhecido) de $\mu$.\
Note que esse resultado não faz nenhuma suposição sobre a distribuição de probabilidade de $\nu$, que é uma variável aleatória.

Como essa analogia se conecta ao problema do aprendizado? Parece que a incógnita aqui é um simples valor $\mu$, enquanto a incógnita em aprendizado é uma função $f: \mathcal{X} \to \mathcal{Y}$. Considere então o seguinte agora: dada uma hipótese $h \in \mathcal{H}$, compare-a com a função desconhecida $f$ em cada um dos pontos $x \in X$. Vamos dizer que $x$ é verde se $h(x) = f(x)$, e vermelho caso $h(x) \neq f(x)$. A cor que cada ponto tem é desconhecida para nós, pois $f$ é desconhecida. Entretanto, se escolhermos $x$ aleatoriamente de acordo com alguma distribuição de probabilidade $P$ sobre o espaço de entrada $\mathcal{X}$, sabemos que $x$ será vermelho com uma probabilidade, diga-se $\mu$, e verde com probabilidade $1 - \mu$.\
Nosso dataset de treino faz a função de amostra aleatória. Se as entradas $x_1, \dots, x_N$ em $\mathcal{D}$ são escolhidas independentemente de acordo com $P$, teremos uma amostra aleatória de pontos vermelhos $(h(x) \neq f(x))$ e verdes $(h(x) = f(x))$. Com essa equivalência, [Desigualdade de Hoeffding](#eq:hoeffding) pode ser aplicada ao problema do aprendizado.\
Infelizmente, não temos total controle sobre $\nu$ em nossa atual situação, pois $\nu$ depende da escolha de nossa hipótese $h$. No aprendizado real, exploramos todo o espaço de hipóteses $\mathcal{H}$, em busca de alguma $h \in \mathcal{H}$ que tenha uma taxa de erro pequena. Se somente temos uma hipótese, não estamos aprendendo, mas somente "verificando" se a nossa hipótese é boa ou ruim.

Vimos que precisamos estender nossa analogia para o caso de trabalharmos com múltiplas hipóteses. Para isso, vamos mudar um pouco a nossa notação. Como ambos $\mu$ (a probabilidade da nossa função $h$ discordar da função objetivo $f$ para um dado $x \in \mathcal{X}$) e $\nu$ (a proporção amostral da quantidade de vezes em que $h$ e $f$ discordam) dependem de $h$, vamos chamar de $E_\text{in}(h)$ a proporção de erros na amostra (para uma hipótese $h$), e de $E_\text{out}(h)$ a probabilidade da nossa hipótese $h$ estar errada para um ponto $x \in \mathcal{X}$ qualquer (Isto é, $\nu = E_\text{in}(h)$ e $\mu = E_\text{out}(h)$). Então, podemos reescrever @eq:hoeffding como:
$$
\mathbb{P}[|E_\text{in}(h) - E_\text{out}(h)| > \epsilon] \leq 2e ^{-2 \epsilon ^ 2 N} \quad \text{para todo } \epsilon > 0
$${#eq:hoeffding2}
onde $N$ é o número de exemplos de treino (ou pontos no dataset).\
Agora, nosso problema é o seguinte: a inequação @eq:hoeffding2 apenas nos diz algo sobre a precisão esperada de uma determinada hipótese $h$, que pode ou não ser a hipótese final escolhida pelo nosso algoritmo, que precisa considerar todo o espaço de hipóteses $\mathcal{H}$.\
Seja então $g \in \mathcal{H}$ a nossa hipótese final, escolhida pelo nosso algoritmo entre as possíveis hipóteses $\{h_1, \dots, h_M\} = \mathcal{H}$. Temos que :
$$
\begin{align*}
   |E_\text{in}(g) - E_\text{out}(g)| > \epsilon \implies
   &|E_\text{in}(h_1) - E_\text{out}(h_1)| > \epsilon\\
   \text{ou }&|E_\text{in}(h_2) - E_\text{out}(h_2)| > \epsilon\\
   \dots \\
   \text{ou }&|E_\text{in}(h_M) - E_\text{out}(h_M)| > \epsilon\\
\end{align*}
$$
Então, podemos escrever:
$$
\begin{align*}
   \mathbb{P}[|E_\text{in}(g) - E_\text{out}(g)| > \epsilon] &\leq
   \mathbb{P}[|E_\text{in}(h_1) - E_\text{out}(h_1)| > \epsilon\\
   &\quad \text{ou }|E_\text{in}(h_2) - E_\text{out}(h_2)| > \epsilon\\
   &\quad \dots \\
   &\quad \text{ou }|E_\text{in}(h_M) - E_\text{out}(h_M)| > \epsilon]\\
   &\leq \sum_{m = 1}^M \mathbb{P}[|E_\text{in}(h_m) - E_\text{out}(h_m)| > \epsilon]
\end{align*}
$$
O que nos dá
$$
\mathbb{P}[|E_\text{in}(g) - E_\text{out}(g)| > \epsilon] \leq
2Me ^{-2 \epsilon ^ 2 N} \quad \text{para todo } \epsilon > 0
$${#eq:hoeffding-multiple}
Note que essa desigualdade só faz sentido se $M$, o tamanho do espaço de hipótese $\mathcal{H}$ for finito.