---
header-includes:
- \usepackage{stmaryrd}
...
# Erro e ruído
Precisamos revisitar dois conceitos do problema do aprendizado para trazê-los mais perto do mundo real. A primeira noção é sobre o que significa dizer que a nossa hipótese $g \in \mathcal{H}$ aproxima a nossa função objetivo $f$. A segunda noção é sobre a natureza da nossa função objetivo. Temos tratado a nossa função objetivo de uma maneira determinística, como uma função real, matematicamente falando. Na imensa maioria das aplicações reais, há um certo ruído que faz com que a saída de $f$ não seja unicamente determinada pela sua entrada (o que faria com que $f$ deixasse de ser uma função, matematicamente falando)

## Medidas de erro
Não esperamos que o aprendizado seja capaz de replicar a nossa função objetivo perfeitamente. A hipótese final $g$ é apenas uma aproximação de $f$. Para quantificar quão bem $g$ aproxima $f$, precisamos de uma medida de erro.\
A escolha de uma medida de erro afeta o resultado do nosso processo de aprendizado, pois nosso algoritmo irá escolher (idealmente) a hipótese que tiver o menor erro possível, dentre as hipóteses analisadas. Então medidas - ou *funções* - de erro distintas podem levar a escolhas de hipóteses finais distintas para o mesmo modelo.

Vamos formalizar este conceito. Uma medida de erro quantifica quão bem cada hipótese $h$ no modelo aproxima a função objetivo $f$, isto é
$$
\text{Erro} = E(h, f)
$$

Enquanto $E(h, f)$ é baseada na totalidade de $h$ e $f$, é quase universalmente definida baseada nos erros de entradas individuais $\mathrm{x}$. Se definirmos uma medida de erro ponto a ponto $\mathrm{e}(h(\mathrm{x}), h(\mathrm{x}))$, o erro geral será a média desses erros pontuais. No perceptron, nossa medida de erro de classificação tem sido
$\mathrm{e}(h(\mathrm{x}), h(\mathrm{x})) = [h(x) \neq f(x)]$, onde
$$
[h(x) \neq f(x)] = \begin{cases}
   1, & \text{caso } h(x) \neq f(x)\\
   0, & \text{caso contrário}
\end{cases}
$$

Em um mundo ideal, $E(h, f)$ deveria ser especificado pelo usuário.